
文本分类任务结果

     model             acc        lr  hidden_size  batch_size pooling_style  train_time  predict_time
0   fast_text  0.887406  0.0010          128          64           avg   10.617064      0.071816       
1   fast_text  0.892827  0.0010          128         128           avg    5.471110      0.058127       
2   fast_text  0.892410  0.0010          256          64           avg   17.647039      0.076473       
3   fast_text  0.889908  0.0010          256         128           avg   10.598747      0.067320       
4   fast_text  0.811093  0.0001          128          64           avg    9.837838      0.084123       
5   fast_text  0.747706  0.0001          128         128           avg    5.905575      0.050989       
6   fast_text  0.833611  0.0001          256          64           avg   17.647832      0.086633       
7   fast_text  0.801084  0.0001          256         128           avg   10.545086      0.062769       
8         rnn  0.891576  0.0010          128          64           avg   40.429087      0.281998       
9         rnn  0.886989  0.0010          128         128           avg   29.174365      0.233187       
10        rnn  0.879066  0.0010          256          64           avg   81.599285      0.554338       
11        rnn  0.888240  0.0010          256         128           avg   69.293166      0.530424       
12        rnn  0.866972  0.0001          128          64           avg   37.826716      0.245463       
13        rnn  0.878649  0.0001          128         128           avg   27.229233      0.208240       
14        rnn  0.883236  0.0001          256          64           avg   81.444906      0.556262       
15        rnn  0.886572  0.0001          256         128           avg   69.086741      0.520921       
16        cnn  0.880317  0.0010          128          64           avg   19.747215      0.130954       
17        cnn  0.883236  0.0010          128         128           avg   15.351383      0.120476       
18        cnn  0.888240  0.0010          256          64           avg   53.208177      0.303660       
19        cnn  0.884904  0.0010          256         128           avg   46.753683      0.337586       
20        cnn  0.860717  0.0001          128          64           avg   18.354121      0.140628       
21        cnn  0.849875  0.0001          128         128           avg   14.618621      0.136430       
22        cnn  0.875730  0.0001          256          64           avg   49.181066      0.298527       
23        cnn  0.870726  0.0001          256         128           avg   42.093858      0.276899       
24  gated_cnn  0.890742  0.0010          128          64           avg   30.318488      0.234021       
25  gated_cnn  0.892410  0.0010          128         128           avg   26.169360      0.218065       
26  gated_cnn  0.885321  0.0010          256          64           avg   86.498125      0.572161       
27  gated_cnn  0.884070  0.0010          256         128           avg   79.750735      0.576048       
28  gated_cnn  0.874479  0.0001          128          64           avg   30.492502      0.242284       
29  gated_cnn  0.866972  0.0001          128         128           avg   26.062524      0.202002       
30  gated_cnn  0.891576  0.0001          256          64           avg   87.161579      0.605808       
31  gated_cnn  0.889074  0.0001          256         128           avg   79.422704      0.536794       
32        gru  0.876981  0.0010          128          64           avg   94.693398      0.603659       
33        gru  0.873228  0.0010          128         128           avg   74.793114      0.553644       
34        gru  0.873645  0.0010          256          64           avg  211.908735      1.426476       
35        gru  0.883653  0.0010          256         128           avg  187.748055      1.361428       
36        gru  0.885321  0.0001          128          64           avg   94.624274      0.623790       
37        gru  0.886572  0.0001          128         128           avg   74.766794      0.520911       
38        gru  0.887406  0.0001          256          64           avg  211.751751      1.392837       
39        gru  0.889908  0.0001          256         128           avg  181.702534      1.308589       
40       lstm  0.880734  0.0010          128          64           avg   60.927097      0.406566       
41       lstm  0.889074  0.0010          128         128           avg   53.705981      0.410571       
42       lstm  0.887406  0.0010          256          64           avg  184.645684      1.232165       
43       lstm  0.879483  0.0010          256         128           avg  168.764289      1.219146       
44       lstm  0.895746  0.0001          128          64           avg   61.296103      0.439649       
45       lstm  0.893661  0.0001          128         128           avg   53.767498      0.425278       
46       lstm  0.883236  0.0001          256          64           avg  184.096405      0.425278       
47       lstm  0.883236  0.0001          256          64           avg  184.096405      1.235474       
48       lstm  0.889908  0.0001          256         128           avg  169.686652      1.365810       
49  0.906589       bert   2e-5             768          64
50  0.910759       bert   2e-5             768         128


-不同的模型在性能和效率之间存在权衡。
例如，`fast_text`和`cnn`在准确率和训练时间上表现较好，而`rnn`、`gru`和`lstm`虽然准确率较高，但训练时间较长。
预训练模型bert准确率最高，能达到90%以上，但消耗时间很长

- 超参数选择的重要性：
选择合适的超参数（如学习率、隐藏层大小、批量大小）对模型性能有显著影响。
例如，对于`fast_text`模型，较小的学习率和较大的批量大小可以提高准确率并缩短训练时间。

- 模型选择的依据：
根据具体任务的需求和资源限制，选择合适的模型。对于需要高效处理的任务，可以选择`fast_text`或`cnn`；
对于需要更高准确率的任务，可以选择`lstm`或`gru`。
若对准确率有更严格的要求，并且资源充足，可以使用bert预训练模型

-其他
对于该任务，lstm与gru相比RNN等简单模型并没有明显准确率的优势，
可能是因为序列本身不是很长，并且该分类任务较为简单，lstm与gru的优势难以体现